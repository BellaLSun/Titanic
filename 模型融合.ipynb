{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #数据分析\n",
    "import numpy as np #科学计算\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the current Axes:<br> https://matplotlib.org/api/_as_gen/matplotlib.pyplot.gca.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/2051744/reverse-y-axis-in-pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型融合可以比较好地缓解，训练过程中产生的过拟合问题，从而对于结果的准确度提升有一定的帮助"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_Pclass_female_1</th>\n",
       "      <th>Sex_Pclass_female_2</th>\n",
       "      <th>Sex_Pclass_female_3</th>\n",
       "      <th>Sex_Pclass_male_1</th>\n",
       "      <th>Sex_Pclass_male_2</th>\n",
       "      <th>Sex_Pclass_male_3</th>\n",
       "      <th>Age_scaled</th>\n",
       "      <th>Fare_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.561380</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613171</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.267742</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392942</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392942</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  SibSp  Parch  Cabin_No  Cabin_Yes  Embarked_C  \\\n",
       "PassengerId                                                            \n",
       "1                   0      1      0         1          0           0   \n",
       "2                   1      1      0         0          1           1   \n",
       "3                   1      0      0         1          0           0   \n",
       "4                   1      1      0         0          1           0   \n",
       "5                   0      0      0         1          0           0   \n",
       "\n",
       "             Embarked_Q  Embarked_S  Sex_female  Sex_male     ...       \\\n",
       "PassengerId                                                   ...        \n",
       "1                     0           1           0         1     ...        \n",
       "2                     0           0           1         0     ...        \n",
       "3                     0           1           1         0     ...        \n",
       "4                     0           1           1         0     ...        \n",
       "5                     0           1           0         1     ...        \n",
       "\n",
       "             Pclass_2  Pclass_3  Sex_Pclass_female_1  Sex_Pclass_female_2  \\\n",
       "PassengerId                                                                 \n",
       "1                   0         1                    0                    0   \n",
       "2                   0         0                    1                    0   \n",
       "3                   0         1                    0                    0   \n",
       "4                   0         0                    1                    0   \n",
       "5                   0         1                    0                    0   \n",
       "\n",
       "             Sex_Pclass_female_3  Sex_Pclass_male_1  Sex_Pclass_male_2  \\\n",
       "PassengerId                                                              \n",
       "1                              0                  0                  0   \n",
       "2                              0                  0                  0   \n",
       "3                              1                  0                  0   \n",
       "4                              0                  0                  0   \n",
       "5                              0                  0                  0   \n",
       "\n",
       "             Sex_Pclass_male_3  Age_scaled  Fare_scaled  \n",
       "PassengerId                                              \n",
       "1                            1   -0.561380    -0.502445  \n",
       "2                            0    0.613171     0.786845  \n",
       "3                            0   -0.267742    -0.488854  \n",
       "4                            0    0.392942     0.420730  \n",
       "5                            1    0.392942    -0.486337  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data_for_ensemble_model.csv',index_col=0)\n",
    "train_df = train_df.set_index('PassengerId')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble 1.1 Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=1e-06,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.8, n_estimators=20, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "train_df = train_df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass.*|Mother|Child|Family|Title')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "# fit到BaggingRegressor之中\n",
    "# 注意，这里是regressor，用0，1进行回归拟合，结果不好\n",
    "bagging_reg = BaggingRegressor(clf, n_estimators=20, max_samples=0.8, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1)\n",
    "bagging_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2463291 , 0.25668329, 0.30093405, 0.19145506, 0.44714355])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(bagging_clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77094972, 0.78212291, 0.82022472, 0.80337079, 0.83615819])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(clf, n_estimators=20, max_samples=0.8, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=-1)\n",
    "bagging_clf.fit(X, y)\n",
    "scores = cross_val_score(bagging_clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Ensemble 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# fit到RandomForestRegressor之中\n",
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                                criterion='gini',\n",
    "                                max_depth=5,\n",
    "                                min_samples_split=10,\n",
    "                                min_samples_leaf=5,\n",
    "                                random_state=0)\n",
    "forest.fit(X, y)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80446927, 0.81005587, 0.81460674, 0.79213483, 0.81355932])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(forest,X,y,scoring='accuracy',cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble 1.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "train_df = pd.read_csv(\"processed_dataset.csv\")\n",
    "train_df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "# Age_.* means any fields begin with Age\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]\n",
    "\n",
    "# fit\n",
    "svm = SVC()\n",
    "svm.fit(X, y)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82681564, 0.82122905, 0.81460674, 0.80898876, 0.84180791])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(svm,x,y,scoring='accuracy',cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble 1.4 More models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/l3r4nd/titanic-prediction-with-svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, plot_importance \n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"processed_dataset.csv\")\n",
    "train_df.drop(\"PassengerId\", axis=1, inplace=True)\n",
    "# Age_.* means any fields begin with Age\n",
    "train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n",
    "train_np = train_df.values\n",
    "\n",
    "# y即Survival结果\n",
    "y = train_np[:, 0]\n",
    "\n",
    "# X即特征属性值\n",
    "X = train_np[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.826101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.824927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.816064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.814902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.804715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.803654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>0.798073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.772318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score\n",
       "XGBoost             0.826101\n",
       "SVM                 0.824927\n",
       "AdaBoost            0.816064\n",
       "RandomForest        0.814902\n",
       "LogisticRegression  0.804715\n",
       "Bagging             0.803654\n",
       "ExtraTrees          0.798073\n",
       "DecisionTree        0.772318"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_et = ExtraTreesClassifier()\n",
    "clf_bc = BaggingClassifier()\n",
    "clf_ada = AdaBoostClassifier()\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_xg = XGBClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "clf_svm = SVC()\n",
    "\n",
    "scores = []\n",
    "models = [clf_rf, clf_et, clf_bc, clf_ada, clf_dt, clf_xg, clf_lr, clf_svm]\n",
    "for model in models:\n",
    "    score = cross_val_score(model, x, y, scoring = 'accuracy', cv = 10, n_jobs = -1).mean()\n",
    "    scores.append(score)\n",
    "    \n",
    "Classifiers = ['RandomForest','ExtraTrees','Bagging','AdaBoost','DecisionTree','XGBoost','LogisticRegression','SVM']\n",
    "mode = pd.DataFrame(scores, index = Classifiers, columns = ['score']).sort_values(by = 'score',\n",
    "             ascending = False)\n",
    "mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble 1.5 Ensemble Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Hyperparameter tunning for best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performed a grid search optimization for XGBoost, SVM , AdaBoost, RandomForest classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/wzmsltw/article/details/50994481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 6, 'n_estimators': 38}, 0.8361391694725028)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "clf =XGBClassifier(learning_rate=0.1, max_depth=2, \n",
    "silent=True, objective='binary:logistic')\n",
    "# 设置boosting迭代计算次数\n",
    "param_test = {\n",
    "    'n_estimators': range(30, 50, 2),\n",
    "    'max_depth': range(2, 7, 1)\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = param_test, \n",
    "scoring='accuracy', cv=5)\n",
    "grid_search.fit(x,y)\n",
    "#grid_search.grid_scores_,\n",
    "grid_search.best_params_,grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8338945005611672"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier(learning_rate=0.1)\n",
    "# 设置boosting迭代计算次数\n",
    "XGB_param_grid = {'n_estimators': range(30, 50, 2),\n",
    "                  'max_depth': range(2, 7, 1)}\n",
    "gsXGB = GridSearchCV(XGB,param_grid = XGB_param_grid,cv=kfold, scoring=\"accuracy\", n_jobs= -1,verbose = 1)\n",
    "gsXGB.fit(x,y)\n",
    "XGB_best = gsXGB.best_estimator_\n",
    "# Best score\n",
    "gsXGB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM=Support Vector Machine 是支持向量\n",
    "- SVC=Support Vector Classification就是支持向量机用于分类，\n",
    "- SVR=Support Vector Regression.就是支持向量机用于回归分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://pic3.zhimg.com/80/v2-413aa22b468d5bbbaf4b4f2c642f1c9a_hd.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM的两个参数 C 和 gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM模型有两个非常重要的参数C与gamma。其中 C是惩罚系数，即对误差的宽容度。\n",
    "- c越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差\n",
    "- **gamma是选择RBF函数作为kernel**后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，**gamma越大，支持向量越少**，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。\n",
    "- 此外大家注意RBF公式里面的sigma和gamma的关系如下：\n",
    "https://blog.csdn.net/wusecaiyun/article/details/49681431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma的物理意义，大家提到很多的RBF的幅宽，它会影响每个支持向量对应的高斯的作用范围，从而影响泛化性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload-images.jianshu.io/upload_images/1825662-e9be9419f3fd85bf.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8305274971941639"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVC classifier\n",
    "SVMC = SVC(probability=True)\n",
    "svc_param_grid = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "gsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "gsSVMC.fit(x,y)\n",
    "\n",
    "SVMC_best = gsSVMC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsSVMC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/pinard/p/6136914.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8294051627384961"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForest\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,300],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsRFC.fit(x,y)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/l3r4nd/titanic-prediction-with-svm\n",
    "    多个模型调参数的循环算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Feature importance of tree based classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the most informative features for the prediction of passengers survival, i displayed the feature importance for the 4 tree based classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Ensemble Model - Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/jiaxin359/p/8777574.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类的机器学习算法输出有两种类型：\n",
    "- 一种是直接输出类标签，硬投票(Majority/Hard voting)：比如有4个模型，3个预测得到类1，1个得到类0，则voting得到1.\n",
    "- 另外一种是输出类概率，叫做软投票(Soft voting)。 sklearn中的VotingClassifier是投票法的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如何确定weight：\n",
    "\n",
    "weighted data。就是把比较难的/容易分错的点的权重提高，简单的点的权重降低。\n",
    "\n",
    "比如一个点的权重是2，那么可以把它当作两个这个点来看待，那么如果这个点分错了，那么error就是2倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingC = VotingClassifier(estimators=[(\"XGBClassifier\", XGB_best),(\"SVM\",SVMC_best),(\"RandomForest\",RFC_best)], voting='soft', n_jobs=4)\n",
    "votingC = votingC.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77777778 0.82222222 0.74157303 0.88764045 0.92134831 0.82022472\n",
      " 0.83146067 0.76404494 0.86516854 0.875     ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(votingC,x,y,scoring='accuracy', cv=10)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于全部分类器的加权求和结果，而这个权重代表的是该分类器在**上一轮迭代中的成功/正确度**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，这个正确率 =  7/10 + 10/13 + 10/13，和正确答案不一样啊。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='322.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/25836678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型M1相当于被训练了2次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='111.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取子集进行训练，可以减少variance，减少过拟合。<br>\n",
    "然后再把predict的test data的结果Vstack。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以上，就得到了**解决过拟合的P1**，然后就可以用P1去训练得到T1了。\n",
    "- 对于测试集T1的得到，有两种方法。\n",
    "- 1. 注意到刚刚是2折交叉验证，M1相当于训练了2次，所以一种方法是每一次训练M1，就开始直接对整个test进行预测，这样2折交叉验证后测试集相当于预测了2次，然后对这两列求平均得到T1。\n",
    "- 2. 或者如上图所示，求完pred并hstack之后，再用M1对测试集进行预测，一次直接得到T1。\n",
    "- 得到了P1，T1，用其他模型M2，M3等得到的P2，T2，P3，T3也是一样的道理。将P1，2，3进行Hstack，T1，2，3进行Hstack，就可以进行下一层的模型训练了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以最终的代码是两层循环，\n",
    "- 第一层循环控制基模型的数目，每一个基模型要这样去得到P1，T1，\n",
    "- 第二层循环控制的是交叉验证的次数K，对每一个基模型，会训练K次最后拼接得到P1，用P1对全体test数据进行predict，然后取平均得到T1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='model stack.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
